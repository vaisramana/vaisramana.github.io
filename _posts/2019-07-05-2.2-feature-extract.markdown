<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                    tex2jax: {
                    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
                    inlineMath: [['$','$']]
                    }
                });
    </script>
</head>

## 2.2 如何萃取，特征提取
与其他机器学习的任务类似，特征提取对于模型训练来说至关重要。

目前最常用的语音特征提取方式是滤波器组Fbank和Mel-Frequency Cepstral Coefficients (MFCCs)。

### Fbank
filter banks包含如下步骤
- 预加重滤波器

预加重处理其实是一个高通滤波器，目的是提升高频部分，使信号的频谱变得平坦，保持在低频到高频的整个频带中，能用同样的信噪比求频谱。同时，也是为了消除发生过程中声带和嘴唇的效应，来补偿语音信号受到发音系统所抑制的高频部分，也为了突出高频的共振峰。

$$
y(t)=x(t)-\mu x(t-1)
$$

其中$\mu$值介于$0.9 - 1$之间

- 语音分帧

语音信号的频率的是时变的，如果在整段语音信号上做傅里叶变换的话，会失去这个时变的包络信息。但是语音信号频率在很短的时间片段内，我们可以认为是是稳定的，因此基于一个短时时间片段做傅里叶变换，可以近似得到信号的频域包络。
我们将一个包含$$N$$个采样点的短时时间片段称为帧，帧长通常为10~30ms左右。为了避免相邻两帧的变化过大，因此会让两相邻帧之间有一段重叠区域，此重叠区域包含了$$M$$个取样点，通常$$M$$的值约为$$N$$的$$\frac{1}{4}$$至$$ \frac{1}{3}$$。
通常语音识别所采用语音信号的采样频率为8kHz或16kHz，以16kHz来说，若帧长度为256个采样点，则对应的时间长度是$$256/16000×1000=16ms$$。
值得注意的是，窗长的选择是频率分辨率和时间分辨率的折中，窗长越大，带宽越小，频率分辨率越明显，但时间分辨率越模糊。窗长越小则结论相反。

- 加窗

上一步分帧的操作相当于在连续的语音流上加了矩形窗截取出有限长片段，应用矩形窗相当于时域相乘，频域卷积，导致在频域除了应有主瓣外，还产生了不该有的旁瓣，我们称之为频谱泄漏。为了减小频谱泄漏，我们会用到一些旁瓣衰减更大的窗函数，比如汉明窗和高斯窗。
如下图所示，矩形窗的旁瓣非常严重，而高斯窗和汉明窗对旁瓣有一定压制作用，减弱频谱泄漏带来的影响。
	![Window_function_(rectangular).svg](/assets/feature-extract/Window_function_(rectangular).svg)
	![Window_function_(gauss).svg](/assets/feature-extract/Window_function_(gauss).svg)
	![Window_function_(hamming).svg](/assets/feature-extract/Window_function_(hamming).svg)

- 短时傅里叶变换STFT

基于每一帧做$$N$$点的FFT，我们称之为短时傅里叶变换Short-Time Fourier-Transform (STFT)，这里$$N$$的典型值是256或者512。然后基于如下公式计算功率谱密度

$$
P=\frac{|FFT(x_{i})|^{2}}{N}
$$

其中$x_{i}$是原始语音$x$的第$$i$$帧

- 梅尔频域滤波器组

在语音唤醒任务里，我们设计出一组滤波器来提取特征，希望能一定程度上体现人耳的特点，从而提高任务准确性。
这里主要涉及两个人耳特性来帮助设计滤波器组

 - 频域感知非线性，指导滤波器组的中心频率
 - 掩蔽效应和临界带宽，指导滤波器组的带宽

人耳对不同频率的声音敏感度不同，就像一个滤波器组一样，它只关注某些特定的频率分量，也就说，它只让某些频段信号通过，而无视它不想感知频段信号。高频和低频的敏感度比较低，如下图所示，30Hz和15kHz的声音需要60dB才能被人耳听到，而1kHZ的声音在0db处就可以听到。
    ![ATH.png](/assets/feature-extract/ATH.png)

同时在感知频率区域内，敏感度也不是均匀分布的，比如在$$(100Hz, 4kHz)$$区域内曲线比较平缓，而5kHz以上曲线就变得陡峭。针对人耳敏感度在频域的这种非线性，我们将语音转换到梅尔Mel刻度，梅尔刻度是一种基于人耳对等距的音高变化的感官判断而定的非线性频率刻度，梅尔刻度和赫兹的转换关系是

$$
m=2595\; log_{10}(1+\frac{f}{700})
\\ f=700\; (10^{\frac{m}{2595}}-1)
$$

在梅尔频域内均匀分布滤波器组，正好线性反映了人耳对音调的感知能力。
人耳在安静的环境中分辨出轻微的声音，但是在嘈杂的环境里，这些轻微的声音就会被杂音所淹没，这个重要特性称为掩蔽效应，举例来说，假设安静环境下听清某声音A的最小分贝是35db，如果此时同时存在另一声音B，由于声音B的存在，听清声音A的最小分贝是40db，比安静环境下提高了5db。此时我们成声音B为掩蔽声，声音A为被掩蔽声，40db称为掩蔽阈。
当两个频率相近的声音同时存在时，两者可能发生掩蔽效应，人耳会把两个声音听成一个。临界带宽指的就是这样一种令人的主观感觉发生突变的带宽边界，当两个声音的频域距离小于临界带宽时，就会产生屏蔽效应。
我们将滤波器组带宽设置为临界带宽，就能模拟人耳的这一特性。
由以上信息，我们可以设计一组基于梅尔频域的三角滤波器，滤波器个数接近临界带宽个数，中心频点在梅尔频域均匀分布，来模拟人耳特性。
    ![mel_filters.jpg](/assets/feature-extract/mel_filters.jpg)

经过梅尔频域滤波器组之后，可以得到如下语谱图，用二维图像信息表达三维语音信息。语谱图的横坐标是时间，纵坐标是频率，坐标点值为语音数据能量，颜色越深，则该点语音能量越强。
    ![spectrogram.png](/assets/feature-extract/spectrogram.png)


### MFCC
MFCC包含完整的FBank操作，在此基础上额外增加了离散余弦变换DCT。
基于上一步FBank得到的频谱对数坐标域上做DCT，相当于做逆FFT转换回时域，因此称为倒谱Cepstrum。从频域转换到倒谱域主要出于两点考虑
- 去相关性
FBank特征之间是高度相关的，DCT用于去除各维特征之间的相关性。
- 数据压缩
DCT的输出维度和输入维度相同，倒谱低频信息体现了包络，这对语音唤醒任务比高频信息更重要，因此输出维度实际可以不用全部保留，比较典型的是保留2到13维，一定程度上实现了数据量的压缩。

MFCC只能反映语音的静态特征，而动态特征可以用这些静态特征的一阶差分或者二阶差分来描述。此外除了倒谱信息，我们还可以加入其它语音特征，比如音高和过零率。

基本上整个FBank/MFCC的处理流程都在尽量模拟人耳的特性，相当于有一个丰富先验知识的专家网络用来提取特征。目前已经有一些论文讨论，类似图像任务一样，让神经网络自主的从时域信号里提取特征，而不是靠专家知识。





















