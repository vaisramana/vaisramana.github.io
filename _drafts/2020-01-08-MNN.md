



<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                    tex2jax: {
                    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
                    inlineMath: [['$','$']]
                    }
                });
    </script>
</head>


## Interpreter
> source/core/Interpreter.cpp

### create net
输入模型文件的构造
```cpp
Interpreter* Interpreter::createFromFile(const char* file)
	std::unique_ptr<FileLoader> loader(new FileLoader(file));
	auto net     = new Content;
  bool success = loader->merge(net->buffer);
  createFromBufferInternal(net);
```

输入是flatbuffers::FlatBufferBuilder的构造，主要便于测试
```cpp
Interpreter* Interpreter::createFromBuffer(const void* buffer, size_t size)
	auto net = new Content;
	::memcpy(net->buffer.get(), buffer, size);
```

Interpreter::createFromFile()和Interpreter::createFromBuffer()内部实际都调用Interpreter::createFromBufferInternal()
```cpp
struct Content {
    AutoStorage<uint8_t> buffer;
    const Net* net = nullptr;
    std::vector<std::unique_ptr<Session>> sessions;
    std::map<const Tensor*, const Session*> tensorMap;
};

Interpreter* Interpreter::createFromBufferInternal(Content* net)
	flatbuffers::Verifier verify((const uint8_t*)(net->buffer.get()), net->buffer.size());
	VerifyNetBuffer(verify);
	// net->buffer是flatbuffers，.get()是flatbuffers schema生成的函数
	net->net = GetNet(net->buffer.get());
    // ./schema/current/MNN_generated.h
    // ./schema/default/MNN.fbs
    inline const MNN::Net *GetNet(const void *buf) {
      return flatbuffers::GetRoot<MNN::Net>(buf);
    }
	new Interpreter(net);
		// 只是flatbuffers指针赋值
		Interpreter::Interpreter(Content* net) {
    	MNN_ASSERT(nullptr != net);
    	// mNet是Interpreter类的成员变量，多个session share同一个mNet
    	mNet      = net;
		}
```

### create session
创建session需要配置文件ScheduleConfig，主要包括
- 前向计算类型，CPU/MPS/METAL/OPENGL/OPENCL/...
- 线程数
- 输入输出tensor名
- 内存选项，normal/high/low
- 功耗选项，normal/high/low
- 精度选项，normal/high/low
- 用户自定义选项
```cpp
/** session schedule config */
struct ScheduleConfig {
    /** which tensor should be kept */
    std::vector<std::string> saveTensors;
    /** forward type */
    MNNForwardType type = MNN_FORWARD_CPU;
    	MNN_FORWARD_CPU = 0,
    	MNN_FORWARD_AUTO = 4,
    	/*Hand write metal*/
    	MNN_FORWARD_METAL = 1,
    	/*Use IOS's MPS instead of hand-write metal, Not Support yet*/
    	MNN_FORWARD_MPS = 2,
    	/*Android / Common Device GPU API*/
    	MNN_FORWARD_OPENCL = 3,
    	MNN_FORWARD_OPENGL = 6,
    	MNN_FORWARD_VULKAN = 7,
    	/*Android 8.1's NNAPI, Not Support yet*/
    	MNN_FORWARD_NN = 5,	
    	/*User can use API from Backend.hpp to add or search Backend*/
    	MNN_FORWARD_USER_0 = 8,
    	MNN_FORWARD_USER_1 = 9,
    	MNN_FORWARD_USER_2 = 10,
    	MNN_FORWARD_USER_3 = 11,
    	MNN_FORWARD_ALL
    /** number of threads in parallel */
    int numThread = 4;
    /** subpath to run */
    struct Path {
        std::vector<std::string> inputs;
        std::vector<std::string> outputs;
        enum Mode {
            /**
             * Op Mode
             * - inputs means the source op, can NOT be empty.
             * - outputs means the sink op, can be empty.
             * The path will start from source op, then flow when encounter the sink op.
             * The sink op will not be compute in this path.
             */
            Op = 0,

            /**
             * Tensor Mode (NOT supported yet)
             * - inputs means the inputs tensors, can NOT be empty.
             * - outputs means the outputs tensors, can NOT be empty.
             * It will find the pipeline that compute outputs from inputs.
             */
            Tensor = 1
        };
        /** running mode */
        Mode mode = Op;
    };
    Path path;
    /** backup backend used to create execution when desinated backend do NOT support any op */
    MNNForwardType backupType = MNN_FORWARD_CPU;
    /** extra backend config */
    BackendConfig* backendConfig = nullptr;
};

struct BackendConfig {
    enum MemoryMode { Memory_Normal = 0, Memory_High, Memory_Low };
    MemoryMode memory = Memory_Normal;
    enum PowerMode { Power_Normal = 0, Power_High, Power_Low };
    PowerMode power = Power_Normal;
    enum PrecisionMode { Precision_Normal = 0, Precision_High, Precision_Low };
    PrecisionMode precision = Precision_Normal;
    /** user defined context */
    union {
        void* sharedContext = nullptr;
        size_t flags; // Valid for CPU Backend
    };
};
```

底层都是调用createMultiPathSession()
```cpp
Session* Interpreter::createSession(const ScheduleConfig& config)
	createMultiPathSession({config});
	
Session* Interpreter::createMultiPathSession(const std::vector<ScheduleConfig>& configs)
	auto info       = Schedule::schedule(mNet->net, configs)
		// source/core/Schedule.cpp
		Schedule::ScheduleInfo Schedule::schedule(const Net* net, const std::vector<ScheduleConfig>& configs)
		// 从flatbuffers获取所有tensor，若有除了dim-0之外的维度出现负数，返回valid=false
		bool valid = _setUpTensorInfo(allTensors, net);
		// 遍历所有config
		for (auto& config : configs)
			compute.type      = _getApprociateType(config, net, allTensors, valid);
				static MNNForwardType _getApprociateType(const ScheduleConfig& config, const Net* net, const std::vector<std::shared_ptr<Tensor>>& allTensors, bool inputShapeValid) {
					遍历所有MNNForwardType类型，
```

### Backend
```cpp
// source/core/Backend.hpp
包含两个虚父类BackendCreator和Backend

- BackendCreator
	// source/backend/metal/MetalBackend.mm
	class MetalBackendCreator : public BackendCreator
	MNNInsertExtraBackendCreator(MNN_FORWARD_METAL, new MetalBackendCreator)
	// source/backend/cpu/CPUBackend.cpp
	struct CPUBackendCreator : BackendCreator
	MNNInsertExtraBackendCreator(MNN_FORWARD_CPU, new CPUBackendCreator)
	// source/backend/arm82/Arm82Backend.cpp
	class Arm82BackendCreator : public BackendCreator
	MNNInsertExtraBackendCreator(MNN_FORWARD_USER_1, &creator)
	// source/backend/opencl/core/OpenCLBackend.cpp
	class CLBackendCreator : public BackendCreator
	MNNInsertExtraBackendCreator(MNN_FORWARD_OPENCL, new CLBackendCreator, true)
	// source/backend/vulkan/backend/VulkanBackend.cpp
	class VulkanBackendCreator : public BackendCreator
	MNNInsertExtraBackendCreator(MNN_FORWARD_VULKAN, new VulkanBackendCreator)
	// source/backend/opengl/GLBackend.cpp
	class GLBackendCreator : public BackendCreator
	MNNInsertExtraBackendCreator(MNN_FORWARD_OPENGL, new GLBackendCreator, true)
	

- Backend
  // source/backend/metal/MetalBackend.hpp
	class MetalBackend final : public Backend
	// source/backend/cpu/CPUBackend.hpp
	class CPUBackend final : public Backend
	// source/backend/arm82/Arm82Backend.hpp
	class Arm82Backend : public Backend
	// source/backend/opencl/core/OpenCLBackend.hpp
	class OpenCLBackend final : public Backend
	// source/backend/vulkan/backend/VulkanBackend.hpp
	class VulkanBackend : public Backend
	// source/backend/opengl/GLBackend.hpp
	class GLBackend : public Backend




// source/core/Backend.cpp
static std::map<MNNForwardType, std::pair<const BackendCreator*, bool>>& GetExtraCreator()
	gExtraCreator是一个static的map，用于映射MNNForwardType -> pair<const BackendCreator*, bool>
	once_flag和call_once保证gExtraCreator只会被new一次
	

// source/core/Backend.cpp
bool MNNInsertExtraBackendCreator(MNNForwardType type, const BackendCreator* creator, bool needCheck)
	GetExtraCreator()获取static的*gExtraCreator
	在gExtraCreator里搜索入参MNNForwardType type
		- if 找到，说明重复插入了，返回false
		- else 没有找到，插入map MNNForwardType -> pair<const BackendCreator*, bool>
	

// source/core/Backend.cpp
const BackendCreator* MNNGetExtraBackendCreator(MNNForwardType type)
	registerBackend();
		// source/core/BackendRegister.cpp
		void registerBackend()
			只调用一次registerCPUBackendCreator()
				// source/backend/cpu/CPUBackend.cpp
				void registerCPUBackendCreator()
					MNNInsertExtraBackendCreator(MNN_FORWARD_CPU, new CPUBackendCreator);
					MNNInsertExtraBackendCreator(MNN_FORWARD_METAL, new MetalBackendCreator)
					MNNInsertExtraBackendCreator(MNN_FORWARD_CPU, new CPUBackendCreator)
					MNNInsertExtraBackendCreator(MNN_FORWARD_USER_1, &creator)
					MNNInsertExtraBackendCreator(MNN_FORWARD_OPENCL, new CLBackendCreator, true)
					MNNInsertExtraBackendCreator(MNN_FORWARD_VULKAN, new VulkanBackendCreator)
					MNNInsertExtraBackendCreator(MNN_FORWARD_OPENGL, new GLBackendCreator, true)
	
	GetExtraCreator()获取static的*gExtraCreator
	在gExtraCreator里搜索入参MNNForwardType type
	if 没有找到，get失败，返回nullptr
	else
		if gExtraCreator[i].needCheck == false，返回gExtraCreator[i].BackendCreator
		else 调用gExtraCreator[i].BackendCreator->onCreate()创建一个Backend
			if check通过，返回gExtraCreator[i].BackendCreator
			else check不通过，返回nullptr
					
	
```

### std::call_once and std::once_flag
