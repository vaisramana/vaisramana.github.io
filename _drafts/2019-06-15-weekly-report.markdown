

# 20190621 W25
## TITAN
- 测试对齐		w.明珠冰程
更新同步xiaotixiaoti和xiaoxiangnihao测试集，测试集工具同步
- 测试工具支持tfr
解决npy格式数据内存占用高，加速测试
- xiaotixiaoti @MCU
	- 训练xiaotixiaoti小模型
	- xradio平台算法库编译		w.南哥谷丰
- xiaoxiangnihao混响环境误激活
	- 幅值问题，将均值信息提出40维fbank，在最后一层再加进去，明显能减少幅值依赖
	- 针对上一次提测在会议室环境误激活高问题，用K18的混响误激活集验证模型性能，能复现混响环境误激活高问题

|                                 | 100h普通误激活 |         | 60h混响误激活  |        |
| ------------------------------- | -------------- | ------- | -------------- | ------ |
|                                 | 0.72 0.51 0.33 |         | 0.94 0.88 0.82 |        |
| anjing_10M10F_600               | 606            | 101.00% | 540            | 90.00% |
| AEC_caocao_5M5F_300             | 210            | 70.00%  | 148            | 49.33% |
| AEC_tiantian_5M5F_300           | 293            | 97.67%  | 224            | 74.67% |
| noise_2m_5M5F_300               | 292            | 97.33%  | 250            | 83.33% |
| noise_3m_5M5F_300               | 302            | 100.67% | 248            | 82.67% |
| office_10M10F_600               | 589            | 98.17%  | 532            | 88.67% |
| xxnh_300_no_agc_noise_3m_scale1 | 43             | 21.50%  | 8              | 4.00%  |
| xxnh_300_no_agc_noise_3m_scale4 | 147            | 73.50%  | 53             | 26.50% |
| wjh overall                     | 6              |         | 5              |        |


## 低精度计算
- 训练
	- 从fctc训练代码分离出model和layer，方便实现训练和inference
	- 训练暂时不更新原有模型任何参数，只更新量化相关参数，保证量化模型性能和非量化模型性能理论上完全一致，任何性能变化都是量化误差引起。后面阶段可以放开用小学习率更新模型参数来适配量化方法。
	- create_training_graph可以支持全自动插入量化op，但是适用范围受限，提取出内部方法MovingAvgQuantize和LastValueQuantize封装在layer实现里，FCTC的卷积层量化已实现
- 测试
	
	- 测试目标是验证量化损失，目前损失定义是量化模型和非量化模型的得分差绝对值
	
	- xiaotixiaoti模型经过1000条测试集训练，1000条测试集共产生$$[156608, 436]$$个得分，其中有46个得分量化误差大于0.5，检查大部分场景是激活字和blank的得分互换
	  ![](../assets/report/0621_quant_cnn_empty.png)
	  ![](../assets/report/0621_quant_cnn_ti.png)


## TODO
- TITAN
	- xiaotixiaoti @MCU
	- xiaoxiangnihao混响环境误激活高，尝试加混响环境误激活集
- 低精度计算
	- 用ctc输出的得分距离作为误差更可靠？
	- fsmn层量化
	- 用测试集外数据做误差验证



# 20190614 W24
## TITAN
- xiaoxiangnihao
	- 小幅值激活问题	w. 冰程
		- 将第一层权重均值加到loss，目的是消除幅值影响，效果类似[3,40]做归一化，前向计算减掉权重均值
		- 调整学习率，有利于模型epoch之间性能稳定性
		- 前两层卷积改成$$3\times3$$ 二维卷积，接pooling将频域减到1，后面TCN结构不变
		- FCTC的基础语料挑选100万，用小学习率finetune一遍TITAN模型，效果不好，误激活和激活同步下降

	- ruoqiruoqi新激活词准备
检查训练语料，办公室环境和安静环境各5000条，检查各50条语音，办公室环境有一半信噪比低于0db，还有办公室人声混入。认为该激活词语料不适合TITAN训练

## AEC数据增强工具
- AEC数据生成工具
输入带参考通道设备录音和训练语料，生成不同信噪比的叠加数据，在经过离线AEC，产生AEC数据增强语料

## 低精度量化
- 量化实现方式
	- tranining，google量化方式可以调用tf接口，优点是实现方便，训练代码只需要加一行就可以实现，缺点是op类型和量化方式受限，非google的量化方式需要自己实现
	- inference，google量化方式需要新实现低精度gemm接口，可以借鉴gemmlowp
- python实现google量化方式inference
FC和CONV2D分别在训练中导出量化信息，前向计算中用量化信息做gemm

## TODO
- TITAN MCU新激活词训练
- 低精度量化



